## Exploratory Data Analysis {.page_break_before}

Extensive data was found, each dataset containing the observations arranged in rows and the independent variables in columns. One of these datasets included up to 85 columns.
Datasets from 2017,2018,2019 are included in this Exploratory Data Analysis.

### Reading the Data

To carry out the first step, the datasets were imported to Visual Studio Code using the CSV library. The datasets were merged into a unified file once the total numbers of columns of each of them were matched to an homegeneus number since it was noticeable that the latest dataset included additional independent variables the first two did not include. The three files were merged into a new database after this first sanity check.

### Cleaning Process

It was found that several independent variables would not provide fruitful information due to missing, unknown or incomplete data. Thus, the datasets were visually inspected to filter out irrelevant or incomplete variables. For instance, information pertaining the location (latitude & longitude, or X & Y coordinates) have not been taken into account. Columns containing codes describing the city, county or ID of the location where the crash took place has also been excluded. Columns involving duplicate information (e.g. two columns describing the same independent variable with a label and a number), traffic structures, etc were also removed. For some other independent variables, information that would have been useful was found to be significantly incomplete such as the number of lanes or type of intersection and therefore it was decided to not include it. Additionaly, independent variables with a high number of labels to describe them such as Railroad Crossing Number were also filtered out since it would not provide handy information for the end-user.

After filtering out the information that will not be utilized for this analysis, the number of independent variables went from 80 to 21.


### Project Objective and Plan Proposal

The objective of this work is to use the Illinois Department of Transportation (IDOT) extensive crash data to be analyzed and, finally, be used for a crash risk prediction model based on main categorical data that can be real-time updated (such as the weather/lighting/pavement conditions). Ideally, it could be used by navigation systems to allert drivers to adopt more cautious behavior as soon as they enter higher-risk sections. 

The plan to be carried out will follow the basic steps described as follows:

1. Read the IDOT's crash data CSV files available as an open data source.
2. Clean the data by deleting unwanted columns, handling missing data, and removing irrelevant observations.
3. Tidy the data by organizing the variables into columns and the observations into rows.
4. Analyze and visualize the data by finding correlations both analytically and graphically.
5. Model a prediction algorithm for crash risk according to categorical variables.
}